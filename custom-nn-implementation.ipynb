{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing all necessary packages\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.transforms import Compose \n# Setting randomness seed to ensure reproducability \ntorch.manual_seed(5) #5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6fkg-7EpJbV","outputId":"2228124a-57b6-4bff-d172-e62b89f3700f","execution":{"iopub.status.busy":"2023-04-11T17:28:39.137616Z","iopub.execute_input":"2023-04-11T17:28:39.137995Z","iopub.status.idle":"2023-04-11T17:28:39.147100Z","shell.execute_reply.started":"2023-04-11T17:28:39.137961Z","shell.execute_reply":"2023-04-11T17:28:39.145986Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x72935d8e3150>"},"metadata":{}}]},{"cell_type":"code","source":"# The following sets the transformations for all images in the test set. This converts it to a tensor, and normalizes it. \n\ntransform = transforms.Compose(\n    [transforms.Resize(32),\n     transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# The following transforms the training images in the same way as the testing images, with the only\n# difference being a 0.35 chance of flipping the image horizontally. \n\ntrain_transform = Compose([\n    transforms.Resize(32),\n    transforms.RandomHorizontalFlip(p=0.35),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])\n\n# Sets batch size of 8\nbatch_size = 8\n\n# Creates trainset and trainloader, applying transformations and batchsize. \n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=train_transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\n# Creates trainset and trainloader, applying transformations and batchsize. \n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\n# Determines classes for the classification. \nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYp59iZvplce","outputId":"6d00b27e-6bf1-4237-a9c5-462caa95325c","execution":{"iopub.status.busy":"2023-04-11T17:28:39.472169Z","iopub.execute_input":"2023-04-11T17:28:39.472939Z","iopub.status.idle":"2023-04-11T17:28:41.173678Z","shell.execute_reply.started":"2023-04-11T17:28:39.472905Z","shell.execute_reply":"2023-04-11T17:28:41.172610Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\nSource of dataloader code: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html","metadata":{"id":"AKRPMarYphhr"}},{"cell_type":"code","source":"# Sets device to be GPU if it is available, and CPU if it is not. \nif torch.cuda.is_available():  \n  dev = \"cuda:0\" \nelse:  \n  dev = \"cpu\"  ","metadata":{"id":"UDJYwaFjn3d4","execution":{"iopub.status.busy":"2023-04-11T17:28:41.175673Z","iopub.execute_input":"2023-04-11T17:28:41.176035Z","iopub.status.idle":"2023-04-11T17:28:41.182338Z","shell.execute_reply.started":"2023-04-11T17:28:41.176005Z","shell.execute_reply":"2023-04-11T17:28:41.181335Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Prints chosen device\nprint(dev)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpW1Z8vCpqzL","outputId":"f1d0d045-fca3-4e9e-d48b-6da06ce09fa1","execution":{"iopub.status.busy":"2023-04-11T17:28:41.183775Z","iopub.execute_input":"2023-04-11T17:28:41.184823Z","iopub.status.idle":"2023-04-11T17:28:41.198258Z","shell.execute_reply.started":"2023-04-11T17:28:41.184782Z","shell.execute_reply":"2023-04-11T17:28:41.197208Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creates model architecture \nclass simple_net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Input: 3x32x32\n        \n\n        # Defines average pooling layers to carry out spatial average pooling. \n        # The layer adapts to the input size of the feature map and pools it down \n        # to a 1x1 value. \n        self.pool = nn.AdaptiveAvgPool2d((1,1))\n\n        # Defines max pooling layer with a kernel size of 2x2.\n        self.max_pool = nn.MaxPool2d(2,2)\n        \n        # Defines average pooling layer with a kernel size of 2x2\n        self.avg_pool = nn.AvgPool2d(2,2)\n        \n        # Defines linear layers which which are used to create vector a. \n        self.linear = nn.Linear(3 * 1 * 1, 3)\n        self.linear2 = nn.Linear(120 * 1 * 1, 3)\n        self.linear3 = nn.Linear(240 * 1 * 1, 3)\n\n        # Defines final output linear layer. \n        self.linear_output = nn.Linear(560*1*1,10)\n        \n        # Defines three convolutional layers, which will make up three blocks within the network. \n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 120, kernel_size = 5, padding = 2)\n        self.conv2 = nn.Conv2d(in_channels = 120, out_channels = 240, kernel_size = 3, padding = 1)\n        self.conv3 = nn.Conv2d(in_channels = 240, out_channels = 560, kernel_size = 3, padding = 1)\n\n        # Defines Batch Normalization \n        # Batch normalizations are used to stabilize the training process. \n        self.batch1 = nn.BatchNorm2d(120)\n        self.batch2 = nn.BatchNorm2d(240)\n        self.batch3 = nn.BatchNorm2d(560)\n    \n    def forward(self, x):\n        \n        ### BLOCK ONE ###\n        \n        # a is generated. \n        a = F.relu(self.linear(torch.flatten(self.pool(x),1)))\n        # three convolutional layers recieve the x input, after which a batch normalisation, an activation function \n        # and pooling layer are applied. \n        conv_output_1 = self.max_pool(F.relu(self.batch1(self.conv1(x))))\n        conv_output_2 = self.max_pool(F.relu(self.batch1(self.conv1(x))))\n        conv_output_3 = self.max_pool(F.relu(self.batch1(self.conv1(x))))\n        combined_conv = []\n        # Each convolutional layer output is multiplied by its respective a value. The for loop goes through each element \n        # of the batch. \n        for i in range(len(a)):\n            combined_conv.append(conv_output_1[i] * a[i][0] + conv_output_2[i] * a[i][1] + conv_output_3[i] * a[i][2])\n        # The stack function is then used to combine the results back into a tensor of dimensions: (batch-size, channel numbers, height, width)\n        O = torch.stack(combined_conv)\n        \n        ### BLOCK TWO ###\n        a = F.relu(self.linear2(torch.flatten(self.pool(O),1)))\n        conv_output_1 = self.max_pool(F.relu(self.batch2(self.conv2(O))))\n        conv_output_2 = self.max_pool(F.relu(self.batch2(self.conv2(O))))\n        conv_output_3 = self.max_pool(F.relu(self.batch2(self.conv2(O))))\n        combined_conv = []\n        for i in range(len(a)):\n            combined_conv.append(conv_output_1[i] * a[i][0] + conv_output_2[i] * a[i][1] + conv_output_3[i] * a[i][2])\n        O_2 = torch.stack(combined_conv)\n        \n        ### BLOCK THREE ###\n        a = F.relu(self.linear3(torch.flatten(self.pool(O_2),1)))\n        conv_output_1 = F.relu(self.batch3(self.conv3(O_2)))\n        conv_output_2 = F.relu(self.batch3(self.conv3(O_2)))\n        conv_output_3 = F.relu(self.batch3(self.conv3(O_2)))\n        combined_conv = []\n        for i in range(len(a)):\n            combined_conv.append(conv_output_1[i] * a[i][0] + conv_output_2[i] * a[i][1] + conv_output_3[i] * a[i][2])\n        O_3 = torch.stack(combined_conv)\n        \n        # Classifier \n        # Spatial average pooling is applied to the output of the last block\n        x = self.pool(O_3)\n        # The tensor is flattened into a flat vector. \n        x = torch.flatten(x, 1)\n        # The final classifier is a linear layer with a relu activation function. \n        x = F.relu(self.linear_output(x))\n        return x\n\n# Network is edefined and sent to the active device\n\nsimple_net = simple_net().to(dev)","metadata":{"id":"FVaVRVCpdlSV","execution":{"iopub.status.busy":"2023-04-11T17:28:41.202036Z","iopub.execute_input":"2023-04-11T17:28:41.202354Z","iopub.status.idle":"2023-04-11T17:28:41.241586Z","shell.execute_reply.started":"2023-04-11T17:28:41.202324Z","shell.execute_reply":"2023-04-11T17:28:41.240679Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Importing optimizer\nimport torch.optim as optim\n# Importing optimizer schedueler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n# Learning rate of 0.0001 is defined. \nlr = 0.001\n\n# CrossEntropyLoss is used to generate a loss value for the network.\ncriterion = nn.CrossEntropyLoss()\n# Stochastic Gradient Descent with momentum of 0.9 is used as the optimizer\noptimizer = optim.SGD(simple_net.parameters(),lr=lr, momentum = 0.9)\n# A learning rate scheduler is defined to lower the learning rate if the validation accuracy is \n# not improved after 6 epochs. \nscheduler = ReduceLROnPlateau(optimizer, 'max', patience = 6, verbose = True)\n\n","metadata":{"id":"sChKl2zGxuyZ","execution":{"iopub.status.busy":"2023-04-11T17:28:41.362765Z","iopub.execute_input":"2023-04-11T17:28:41.363062Z","iopub.status.idle":"2023-04-11T17:28:41.369485Z","shell.execute_reply.started":"2023-04-11T17:28:41.363036Z","shell.execute_reply":"2023-04-11T17:28:41.368209Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Lists are defined to store accuracies, loss, epochs and the learning rate over time for evaluation purposes\ntraining_accuracies = []\ntesting_accuracies = []\nloss_over_time = []\nepochs = []\nlearning_rates = []\n# Number of epochs is defined\nepoch_num = 35\n# Loops through the dataset for the predefined number of epochs\nfor epoch in range(epoch_num):  \n\n    running_loss = 0.0\n    epoch_loss = []\n    for i, data in enumerate(trainloader, 0):\n        # Inputs are extracted from the train set dataloader. \n        inputs, labels = data\n        # Data is then sent to the gpu.\n        inputs, labels = inputs.to(dev), labels.to(dev)\n\n        # Gradients are set to zero to ensure gradients from the previous loop are not left over. \n        optimizer.zero_grad()\n\n        # The network produces an input\n        outputs = simple_net(inputs)\n        # A loss value is calculated\n        loss = criterion(outputs, labels)\n        # Gradients for the loss are generated \n        loss.backward()\n        # Gradients are used to update optimizer\n        optimizer.step()\n          \n        epoch_loss.append(loss.item())\n        # Loss is kept track of and printed throughout each epoch. \n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n            \n    #keeps track of epoch loss and computes an average\n    loss_over_time.append(sum(epoch_loss)/len(epoch_loss))\n    # Correct prediction variables are created to allow further evaluation. \n    train_correct = 0\n    train_total = 0\n    \n    # torch.no_grad() is set to ensure the gradients are not updated whilst the model is being evaluated \n    # on the training data\n    with torch.no_grad():\n        for train_data in trainloader:\n            # Data is loaded\n            train_images, train_labels = train_data\n                # Data is sent to gpu\n            train_images, train_labels = train_images.to(dev), train_labels.to(dev)\n                # Data is put through model\n            train_outputs = simple_net(train_images)\n                # Predictions are extracted\n            _, predicted = torch.max(train_outputs.data, 1)\n                # Total predictions and correct predictions are updated \n                # to calculate accuracy metric. \n            train_total += train_labels.size(0)\n            train_correct += (predicted == train_labels).sum().item()\n    \n    # Training accuracies are added to their list and printed. \n    training_accuracies.append(100 * train_correct // train_total)\n    print(f'Training accuracy of the network on the 10000 test images: {100 * train_correct // train_total} %')\n    \n    # The process of assessing the model on the validation set is the same as assessing it on the training set\n    # with the only difference being that the simple_net.eval() is put the model into its evlauation mode. \n    test_correct = 0\n    test_total = 0\n    # since we're not training, we don't need to calculate the gradients for our outputs\n    simple_net.eval()\n    with torch.no_grad():\n        for test_data in testloader:\n            test_images, test_labels = test_data\n            test_images, test_labels = test_images.to(dev), test_labels.to(dev)\n            # calculate outputs by running images through the network\n            test_outputs = simple_net(test_images)\n            # the class with the highest energy is what we choose as prediction\n            _, predicted = torch.max(test_outputs.data, 1)\n            test_total += test_labels.size(0)\n            test_correct += (predicted == test_labels).sum().item()\n    testing_accuracies.append(100 * test_correct // test_total)\n    print(f'Test accuracy of the network on the 10000 test images: {100 * test_correct // test_total} %')\n    simple_net.train()\n    \n    \n    epochs.append(epoch)\n    \n    # The scheduler is given the test accuracy to check whether it needs to update the learning rate. \n    scheduler.step(100 * test_correct // test_total)\n\n    for param_group in optimizer.param_groups:\n         learning_rates.append(param_group['lr'])\n\nprint('Finished Training')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMSYCcXYMCZ5","outputId":"6d20ec94-153c-45a8-de2d-a7c26fef1b1d","execution":{"iopub.status.busy":"2023-04-11T17:28:41.425842Z","iopub.execute_input":"2023-04-11T17:28:41.426198Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[1,  2000] loss: 2.182\n[1,  4000] loss: 1.775\n[1,  6000] loss: 1.624\nTraining accuracy of the network on the 10000 test images: 46 %\nTest accuracy of the network on the 10000 test images: 49 %\n[2,  2000] loss: 1.523\n[2,  4000] loss: 1.457\n[2,  6000] loss: 1.403\nTraining accuracy of the network on the 10000 test images: 50 %\nTest accuracy of the network on the 10000 test images: 54 %\n[3,  2000] loss: 1.341\n[3,  4000] loss: 1.258\n[3,  6000] loss: 1.103\nTraining accuracy of the network on the 10000 test images: 63 %\nTest accuracy of the network on the 10000 test images: 66 %\n[4,  2000] loss: 1.042\n[4,  4000] loss: 1.019\n[4,  6000] loss: 1.003\nTraining accuracy of the network on the 10000 test images: 65 %\nTest accuracy of the network on the 10000 test images: 69 %\n[5,  2000] loss: 0.959\n[5,  4000] loss: 0.925\n[5,  6000] loss: 0.918\nTraining accuracy of the network on the 10000 test images: 70 %\nTest accuracy of the network on the 10000 test images: 73 %\n[6,  2000] loss: 0.850\n[6,  4000] loss: 0.868\n[6,  6000] loss: 0.860\nTraining accuracy of the network on the 10000 test images: 71 %\nTest accuracy of the network on the 10000 test images: 73 %\n[7,  2000] loss: 0.822\n[7,  4000] loss: 0.794\n[7,  6000] loss: 0.801\nTraining accuracy of the network on the 10000 test images: 74 %\nTest accuracy of the network on the 10000 test images: 76 %\n[8,  2000] loss: 0.762\n[8,  4000] loss: 0.759\n[8,  6000] loss: 0.739\nTraining accuracy of the network on the 10000 test images: 75 %\nTest accuracy of the network on the 10000 test images: 77 %\n[9,  2000] loss: 0.719\n[9,  4000] loss: 0.708\n[9,  6000] loss: 0.701\nTraining accuracy of the network on the 10000 test images: 78 %\nTest accuracy of the network on the 10000 test images: 78 %\n[10,  2000] loss: 0.669\n[10,  4000] loss: 0.678\n[10,  6000] loss: 0.667\nTraining accuracy of the network on the 10000 test images: 78 %\nTest accuracy of the network on the 10000 test images: 78 %\n[11,  2000] loss: 0.634\n[11,  4000] loss: 0.641\n[11,  6000] loss: 0.627\nTraining accuracy of the network on the 10000 test images: 80 %\nTest accuracy of the network on the 10000 test images: 79 %\n[12,  2000] loss: 0.598\n[12,  4000] loss: 0.607\n[12,  6000] loss: 0.604\nTraining accuracy of the network on the 10000 test images: 80 %\nTest accuracy of the network on the 10000 test images: 79 %\n[13,  2000] loss: 0.563\n[13,  4000] loss: 0.566\n[13,  6000] loss: 0.578\nTraining accuracy of the network on the 10000 test images: 82 %\nTest accuracy of the network on the 10000 test images: 80 %\n[14,  2000] loss: 0.538\n[14,  4000] loss: 0.537\n[14,  6000] loss: 0.549\nTraining accuracy of the network on the 10000 test images: 83 %\nTest accuracy of the network on the 10000 test images: 81 %\n[15,  2000] loss: 0.507\n[15,  4000] loss: 0.511\n[15,  6000] loss: 0.524\nTraining accuracy of the network on the 10000 test images: 84 %\nTest accuracy of the network on the 10000 test images: 81 %\n[16,  2000] loss: 0.494\n[16,  4000] loss: 0.498\n[16,  6000] loss: 0.488\nTraining accuracy of the network on the 10000 test images: 85 %\nTest accuracy of the network on the 10000 test images: 82 %\n[17,  2000] loss: 0.466\n[17,  4000] loss: 0.471\n[17,  6000] loss: 0.481\nTraining accuracy of the network on the 10000 test images: 84 %\nTest accuracy of the network on the 10000 test images: 81 %\n[18,  2000] loss: 0.447\n[18,  4000] loss: 0.445\n[18,  6000] loss: 0.460\nTraining accuracy of the network on the 10000 test images: 86 %\n[19,  4000] loss: 0.433\n[19,  6000] loss: 0.427\nTraining accuracy of the network on the 10000 test images: 85 %\nTest accuracy of the network on the 10000 test images: 82 %\n[20,  2000] loss: 0.408\n[20,  4000] loss: 0.408\n[20,  6000] loss: 0.401\nTraining accuracy of the network on the 10000 test images: 88 %\nTest accuracy of the network on the 10000 test images: 83 %\n[21,  2000] loss: 0.376\n[21,  4000] loss: 0.390\n[21,  6000] loss: 0.394\nTraining accuracy of the network on the 10000 test images: 88 %\nTest accuracy of the network on the 10000 test images: 83 %\n[22,  2000] loss: 0.363\n[22,  4000] loss: 0.380\n[22,  6000] loss: 0.373\nTraining accuracy of the network on the 10000 test images: 88 %\nTest accuracy of the network on the 10000 test images: 83 %\n[23,  2000] loss: 0.354\n[23,  4000] loss: 0.351\n[23,  6000] loss: 0.354\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"id":"Z_jXmWnNdlSf","execution":{"iopub.status.busy":"2023-04-11T17:28:18.523047Z","iopub.status.idle":"2023-04-11T17:28:18.523852Z","shell.execute_reply.started":"2023-04-11T17:28:18.523580Z","shell.execute_reply":"2023-04-11T17:28:18.523611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8d7DhZDIdlSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"85XlJTaLdlSm"},"execution_count":null,"outputs":[]}]}